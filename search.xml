<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>huggingface_trainer</title>
    <url>/2024/07/06/huggingface-trainer/</url>
    <content><![CDATA[<p><img src="https://github.com/threegold116/picx-images-hosting/raw/master/20240707/721.6bgy8zq948.webp" alt="721"></p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2024/07/06/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>文本生成评估指标</title>
    <url>/2024/07/06/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<blockquote>
<p><strong>references</strong>:</p>
<p><a href="https://leezhao415.github.io/2021/08/08/%E5%B8%B8%E8%A7%81%E7%9A%84NLG%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/">常见的NLG评估指标 | 且听风吟，御剑于心！ (leezhao415.github.io)</a></p>
<p><a href="https://mingchao.wang/q2h3G8DU/#22-textrouge-ltextrouge-l">Index - 笔记 (mingchao.wang)</a></p>
<p><a href="https://wsntxxn.github.io/2020/07/08/NLG-Caption-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E6%80%BB%E7%BB%93/">https://wsntxxn.github.io/2020/07/08/NLG-Caption-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E6%80%BB%E7%BB%93/</a></p>
<p><a href="https://www.wehelpwin.com/article/4126">【NLP技术分享】文本生成评价指标的进化与推翻 - AI魔法学院 (wehelpwin.com)</a></p>
</blockquote>
<blockquote>
<p>tools:</p>
<p><a href="https://github.com/Maluuba/nlg-eval">https://github.com/Maluuba/nlg-eval</a></p>
<p><a href="https://pypi.org/project/nlg-metricverse/">https://pypi.org/project/nlg-metricverse/</a></p>
<p><a href="https://www.cnblogs.com/bonelee/p/18152511">ROUGE指标计算方法和示例 - bonelee - 博客园 (cnblogs.com)</a></p>
<p><a href="https://github.com/tylin/coco-caption">https://github.com/tylin/coco-caption</a></p>
</blockquote>
<h4 id="1-机器自动化指标"><a href="#1-机器自动化指标" class="headerlink" title="1.机器自动化指标"></a>1.机器自动化指标</h4><h5 id="1-1-BLEU-Bilingual-Evaluation-Understudy（双语评估研究）"><a href="#1-1-BLEU-Bilingual-Evaluation-Understudy（双语评估研究）" class="headerlink" title="1.1 BLEU     [Bilingual Evaluation Understudy（双语评估研究）]"></a>1.1 BLEU     [Bilingual Evaluation Understudy（双语评估研究）]</h5><blockquote>
<p>n-gram的加权平均准确率：</p>
<p><a href="https://blog.csdn.net/qq_30232405/article/details/104219396">https://blog.csdn.net/qq_30232405/article/details/104219396</a></p>
</blockquote>
<ul>
<li>得到每个n-gram的准确率</li>
</ul>
<p>$$<br>p_{n}&#x3D;\frac{\sum_{C \in \text { Candidate }} \sum_{\text {gram }<em>{n} \in C} \operatorname{Count}</em>{\text {clip }}\left(\text { gram }<em>{n}\right)}{\sum</em>{C^{\prime} \in \text { Candidate }} \sum_{\text {gram }<em>{n} \in C^{\prime}} \operatorname{Count}</em>{\left(\operatorname{gram}_{n}\right)}}<br>$$</p>
<ul>
<li>加权平均+惩罚因子</li>
</ul>
<p>· 它的易于计算且速度快，特别是与人工翻译模型的输出对比；</p>
<p>· 它应用范围广泛，这可以让你很轻松将模型与相同任务的基准作对比。</p>
<p>· 它不考虑语义，句子结构</p>
<p>· 不能很好地处理形态丰富的语句（BLEU原文建议大家配备4条翻译参考译文）</p>
<p>· BLEU 指标偏向于较短的翻译结果（brevity penalty 没有想象中那么强）</p>
<h5 id="1-2-ROUGE-Recall-Oriented-Understudy-for-Gisting-Evaluation-以召回为导向的要点评估研究"><a href="#1-2-ROUGE-Recall-Oriented-Understudy-for-Gisting-Evaluation-以召回为导向的要点评估研究" class="headerlink" title="1.2 ROUGE [Recall-Oriented Understudy for Gisting Evaluation (以召回为导向的要点评估研究)]"></a>1.2 ROUGE [Recall-Oriented Understudy for Gisting Evaluation (以召回为导向的要点评估研究)]</h5><blockquote>
<p><a href="https://lpq29743.github.io/artificialintelligence/2018/09/28/ROUGE&BLEU/">https://lpq29743.github.io/artificialintelligence/2018/09/28/ROUGE&amp;BLEU/</a></p>
<p><a href="https://aclanthology.org/W04-1013.pdf">https://aclanthology.org/W04-1013.pdf</a> (原始论文)</p>
</blockquote>
<p>ROUGE 用作机器翻译评价指标的初衷是这样的：在 SMT（统计机器翻译）时代，机器翻译效果稀烂，需要同时评价翻译的准确度和流畅度；等到 NMT （神经网络机器翻译）出来以后，神经网络脑补能力极强，翻译出的结果都是通顺的，但是有时候容易瞎翻译。</p>
<p>ROUGE的出现很大程度上是为了解决NMT的漏翻问题（低召回率）。所以 ROUGE 只适合评价 NMT，而不适用于 SMT，因为它不管候选译文流不流畅</p>
<h6 id="ROUGE-N"><a href="#ROUGE-N" class="headerlink" title="ROUGE-N"></a>ROUGE-N</h6><ul>
<li>n-gram的召回率</li>
</ul>
<h6 id="ROUGE-L"><a href="#ROUGE-L" class="headerlink" title="ROUGE-L"></a>ROUGE-L</h6><ul>
<li>最长公共子序列的F值(带$\beta&#x3D;\dfrac{P}{R}$)</li>
<li>词袋模型，它们都不考虑词语之间的相对顺序</li>
<li>这个名字里的 L𝐿 表示的是Longest Common Subsequence（最长公共子序列：注意这个非连续的）</li>
</ul>
<h6 id="ROUGH-W"><a href="#ROUGH-W" class="headerlink" title="ROUGH-W"></a>ROUGH-W</h6><ul>
<li>在ROUGE-L基础上</li>
<li>给连续匹配到的子序列更高的权重，最终让连续匹配的结果要比非连续匹配的结果得分更高一些。</li>
<li>函数选择</li>
</ul>
<h6 id="ROUGH-S"><a href="#ROUGH-S" class="headerlink" title="ROUGH-S"></a>ROUGH-S</h6><ul>
<li>在ROUGE-N基础上</li>
<li>在Rouge-S 中使用的 skip-bigram 则是在划分时允许跳过一些词。</li>
</ul>
<h5 id="1-3-METEOR-an-automatic-metric-for-machine-translation-evaluation-that-is-based-on-a-generalized-concept-of-unigram-matching-between-the-machineproduced-translation-and-human-produced-reference-translations"><a href="#1-3-METEOR-an-automatic-metric-for-machine-translation-evaluation-that-is-based-on-a-generalized-concept-of-unigram-matching-between-the-machineproduced-translation-and-human-produced-reference-translations" class="headerlink" title="1.3 METEOR [an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations ]"></a>1.3 METEOR [an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations ]</h5><blockquote>
<p><a href="https://www.cs.cmu.edu/~alavie/METEOR/pdf/Banerjee-Lavie-2005-METEOR.pdf">https://www.cs.cmu.edu/~alavie/METEOR/pdf/Banerjee-Lavie-2005-METEOR.pdf</a> </p>
<p><a href="https://www.cs.cmu.edu/~alavie/METEOR/index.html">https://www.cs.cmu.edu/~alavie/METEOR/index.html</a> (官网)</p>
</blockquote>
<p>和BLEU不同，METEOR同时考虑了基于整个语料库上的准确率和召回率，而最终得出测度。</p>
<p>METEOR也包括其他指标没有发现一些其他功能，如****同义词匹配****等。METEOR用 WordNet 等知识源扩充了一下同义词集，同时考虑了单词的词形（词干相同的词也认为是部分匹配的，也应该给予一定的奖励，比如说把 likes 翻译成了 like 总比翻译成别的乱七八糟的词要好吧？）</p>
<p>****在评价句子流畅性的时候，用了 chunk 的概念****（候选译文和参考译文能够对齐的、空间排列上连续的单词形成一个 chunk，这个对齐算法是一个有点复杂的启发式 beam serach），chunk 的数目越少意味着每个 chunk 的平均长度越长，也就是说候选译文和参考译文的语序越一致。</p>
<p>BLEU、ROUGE仅统计单词&amp;短语级别的命中，对于近义词、词与词之间的语义关系完全没有考虑(字符串匹配)</p>
<ul>
<li>对齐</li>
<li>求解F+惩罚因子</li>
</ul>
<h5 id="1-4-CIDER-Consensus-based-Image-Description-Evaluation-基于共识的图像描述评估"><a href="#1-4-CIDER-Consensus-based-Image-Description-Evaluation-基于共识的图像描述评估" class="headerlink" title="1.4 CIDER [Consensus-based Image Description Evaluation (基于共识的图像描述评估) ]"></a>1.4 CIDER [Consensus-based Image Description Evaluation (基于共识的图像描述评估) ]</h5><blockquote>
<p><a href="https://arxiv.org/pdf/1411.5726">https://arxiv.org/pdf/1411.5726</a></p>
<p><a href="https://provenclei.github.io/2020/02/01/TF-IDF.html">https://provenclei.github.io/2020/02/01/TF-IDF.html</a></p>
</blockquote>
<p>它的思路跳出了数 n−gram𝑛−𝑔𝑟𝑎𝑚 的 overlap 的框架，它把 candidate 和 reference 都 encode 成一个向量，然后用两个向量的余弦相似度表示 caption 的质量，多个 reference 的情况下就是和各个 reference 算出来的分数的平均。</p>
<ul>
<li><p>利用$TF-IDF$思想计算CIDE</p>
</li>
<li><p>计算每个n-gram长度对于余弦向量的相似度$CIDEr_{n}$</p>
</li>
<li><p>平均得到$CIDEr$</p>
</li>
</ul>
<blockquote>
<p><strong>0~1</strong></p>
</blockquote>
<h6 id="CIDERD"><a href="#CIDERD" class="headerlink" title="CIDERD"></a>CIDERD</h6><blockquote>
<p><strong>0~10</strong></p>
</blockquote>
<ul>
<li>计算长度惩罚因子</li>
</ul>
<h5 id="1-5-SPICE-Semantic-Propositional-Image-Caption-Evaluation-语义命题图像标题评估"><a href="#1-5-SPICE-Semantic-Propositional-Image-Caption-Evaluation-语义命题图像标题评估" class="headerlink" title="1.5 SPICE [Semantic Propositional Image Caption Evaluation (语义命题图像标题评估)]"></a>1.5 SPICE [Semantic Propositional Image Caption Evaluation (语义命题图像标题评估)]</h5><blockquote>
<p><a href="https://panderson.me/spice/">https://panderson.me/spice/</a> </p>
</blockquote>
<ul>
<li>不利用n-gram,利用scene graph<ul>
<li>目标，属性，关系</li>
</ul>
</li>
<li>得到场景图（图论的图），转换为元组集合</li>
<li>计算F值，字符串匹配+近义词+。。。</li>
</ul>
<h5 id="1-7-NIST"><a href="#1-7-NIST" class="headerlink" title="1.7 NIST"></a>1.7 NIST</h5><h5 id="1-8-TER"><a href="#1-8-TER" class="headerlink" title="1.8 TER"></a>1.8 TER</h5><h5 id="1-9-relation-generation-RG-content-selection-CS-content-ordering-CO-Coverage"><a href="#1-9-relation-generation-RG-content-selection-CS-content-ordering-CO-Coverage" class="headerlink" title="1.9 relation generation (RG) content selection (CS) content ordering (CO) Coverage"></a>1.9 relation generation (RG) content selection (CS) content ordering (CO) Coverage</h5><blockquote>
<p><a href="https://github.com/harvardnlp/data2text">https://github.com/harvardnlp/data2text</a></p>
</blockquote>
<ul>
<li>data to text</li>
</ul>
<h5 id="1-10-Distinct"><a href="#1-10-Distinct" class="headerlink" title="1.10 Distinct"></a>1.10 Distinct</h5><h4 id="2-基于词向量指标"><a href="#2-基于词向量指标" class="headerlink" title="2.基于词向量指标"></a>2.基于词向量指标</h4><h5 id="2-1-Greedy-Matching"><a href="#2-1-Greedy-Matching" class="headerlink" title="2.1 Greedy Matching"></a>2.1 Greedy Matching</h5><h5 id="2-2-Embedding-Average"><a href="#2-2-Embedding-Average" class="headerlink" title="2.2 Embedding Average"></a>2.2 Embedding Average</h5><h5 id="2-3-Vector-Extrema"><a href="#2-3-Vector-Extrema" class="headerlink" title="2.3 Vector Extrema"></a>2.3 Vector Extrema</h5><h4 id="3-基于语言模型指标"><a href="#3-基于语言模型指标" class="headerlink" title="3.基于语言模型指标"></a>3.基于语言模型指标</h4><h5 id="3-1-Perplexity"><a href="#3-1-Perplexity" class="headerlink" title="3.1 Perplexity"></a>3.1 Perplexity</h5><h5 id="3-2-bertscore"><a href="#3-2-bertscore" class="headerlink" title="3.2 bertscore"></a>3.2 bertscore</h5><h6 id="BLEURT"><a href="#BLEURT" class="headerlink" title="BLEURT"></a>BLEURT</h6><h6 id="MoverScore"><a href="#MoverScore" class="headerlink" title="MoverScore"></a>MoverScore</h6><h4 id="4-基于人类的指标"><a href="#4-基于人类的指标" class="headerlink" title="4. 基于人类的指标"></a>4. 基于人类的指标</h4><h4 id="开源库对比"><a href="#开源库对比" class="headerlink" title="开源库对比"></a>开源库对比</h4><p><a href="https://github.com/disi-unibo-nlp/nlg-metricverse/blob/main/comparison.md">https://github.com/disi-unibo-nlp/nlg-metricverse/blob/main/comparison.md</a></p>
<p><a href="https://github.com/Maluuba/nlg-eval">https://github.com/Maluuba/nlg-eval</a></p>
]]></content>
  </entry>
</search>
